# -*- coding: utf-8 -*-
"""fetch_and_process_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15W94QYBKK4zxLTB5y8vA6ZB-1Xr0tSaY
"""

import os
import requests
import pandas as pd
from datetime import datetime

# API key and BLS endpoint URL
api_key = "86b67e98f5134a7386ce62902a756492"  
url = "https://api.bls.gov/publicAPI/v2/timeseries/data/"

# Define the series IDs (e.g., non-farm workers and unemployment rate)
series_ids = [
    "CES0000000001",  
    "LNS14000000"     
]

local_data_file = "bls_data.csv"


def fetch_bls_data(start_year, end_year):
    payload = {
        "seriesid": series_ids,
        "startyear": start_year,
        "endyear": end_year,
        "registrationkey": api_key
    }
    response = requests.post(url, json=payload)

    if response.status_code == 200:
        data = response.json()
        if data.get("status") == "REQUEST_SUCCEEDED":
            return data
        else:
            print("Error:", data.get("message"))
    else:
        print("HTTP Error:", response.status_code)

    return None


def process_bls_data(data):
    all_data = []

    for series in data["Results"]["series"]:
        series_id = series["seriesID"]
        for item in series["data"]:
            all_data.append({
                "series_id": series_id,
                "date": datetime.strptime(f"{item['year']} {item['periodName']}", "%Y %B"),
                "value": float(item["value"])
            })

    return pd.DataFrame(all_data)


def load_local_data(file_path):
    if os.path.exists(file_path):
        return pd.read_csv(file_path, parse_dates=["date"])
    else:
        return pd.DataFrame(columns=["series_id", "date", "value"])


def save_local_data(data, file_path):
    data.to_csv(file_path, index=False)


def update_data():
    local_data = load_local_data(local_data_file)

    if not local_data.empty:
        latest_date = local_data["date"].max()
        start_year = latest_date.year
    else:
        start_year = datetime.now().year

    end_year = datetime.now().year

    new_data = fetch_bls_data(start_year, end_year)

    if new_data:
        new_data_df = process_bls_data(new_data)

        combined_data = pd.concat([local_data, new_data_df]).drop_duplicates()

        save_local_data(combined_data, local_data_file)
        print("Data updated successfully.")
    else:
        print("No new data fetched.")


if __name__ == "__main__":
    update_data()
